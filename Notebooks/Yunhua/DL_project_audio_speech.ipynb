{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.io.wavfile as wav\n",
    "from speechpy.feature import mfcc\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = 'C:\\\\Users\\\\ZhaoY\\\\Downloads\\\\DL_Project\\\\dataset\\\\Audio_Speech_Actors_01-24\\\\'\n",
    "dir_list = os.listdir(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Audio_Speech_Actors_01-24\\ hahaha\n"
     ]
    }
   ],
   "source": [
    "#get the paths\n",
    "dirts = []\n",
    "filepath_delete = True\n",
    "for root, dirt,file in os.walk(FILEPATH):\n",
    "    if filepath_delete == True:\n",
    "        print(root, \"hahaha\")\n",
    "        filepath_delete = False\n",
    "    else:\n",
    "        dirts.append(root)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the files in every path\n",
    "files = []\n",
    "for dirt in dirts:\n",
    "    for root, dt, file in os.walk(dirt):\n",
    "        for fl in file:\n",
    "            files.append(os.path.join(dirt,fl))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ZhaoY\\\\Downloads\\\\DL_Project\\\\dataset\\\\Audio_Speech_Actors_01-24\\\\Actor_01\\\\03-01-01-01-01-02-01.wav'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = []\n",
    "Actor = []\n",
    "for file in files:\n",
    "    filename.append(file.split('\\\\')[-1])\n",
    "    Actor.append(file.split('\\\\')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-01-01-01-01-01.wav'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actor_24'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actor[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modality = []\n",
    "Vocal_channel = []\n",
    "Emotion = []\n",
    "Emotional_intensity = []\n",
    "Statement = []\n",
    "Repetition = []\n",
    "\n",
    "for name in filename:\n",
    "    Modality.append(name.split('-')[0])\n",
    "    Vocal_channel.append(name.split('-')[1])\n",
    "    Emotion.append(int(name.split('-')[2])-1)\n",
    "    Emotional_intensity.append(name.split('-')[3])\n",
    "    Statement.append(name.split('-')[4])\n",
    "    Repetition.append(name.split('-')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'files': files, \n",
    "                   'modalities': Modality,\n",
    "                   'vocal_channels': Vocal_channel, \n",
    "                   'emotions': Emotion,\n",
    "                   'emotional_intensities': Emotional_intensity,\n",
    "                   'statements': Statement,\n",
    "                   'repetitiona': Repetition})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>modalities</th>\n",
       "      <th>vocal_channels</th>\n",
       "      <th>emotions</th>\n",
       "      <th>emotional_intensities</th>\n",
       "      <th>statements</th>\n",
       "      <th>repetitiona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Au...</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               files modalities  \\\n",
       "0  C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Au...         03   \n",
       "\n",
       "  vocal_channels  emotions emotional_intensities statements repetitiona  \n",
       "0             01         0                    01         01          01  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1440 entries, 0 to 1439\n",
      "Data columns (total 7 columns):\n",
      "files                    1440 non-null object\n",
      "modalities               1440 non-null object\n",
      "vocal_channels           1440 non-null object\n",
      "emotions                 1440 non-null int64\n",
      "emotional_intensities    1440 non-null object\n",
      "statements               1440 non-null object\n",
      "repetitiona              1440 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    192\n",
       "6    192\n",
       "5    192\n",
       "4    192\n",
       "3    192\n",
       "2    192\n",
       "1    192\n",
       "0     96\n",
       "Name: emotions, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_signal_length = 0\n",
    "signals = []\n",
    "for fname in files:\n",
    "    signal, fs = librosa.load(fname, sr=16000, mono=True)\n",
    "    mean_signal_length += len(signal)\n",
    "    signals.append(signal)\n",
    "mean_signal_length = mean_signal_length/(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59210\n"
     ]
    }
   ],
   "source": [
    "mean_signal_length = int(mean_signal_length) \n",
    "print(mean_signal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector_from_mfcc(signal, mean_signal_length: int, flatten: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make feature vector from MFCC for the given wav file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): path to the .wav file that needs to be read.\n",
    "        flatten (bool) : Boolean indicating whether to flatten mfcc obtained.\n",
    "        mfcc_len (int): Number of cepestral co efficients to be consider.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: feature vector of the wav file made from mfcc.\n",
    "    \"\"\"\n",
    "    #fs, signal = wav.read(file_path)\n",
    "    #signal, fs = librosa.load(file_path, sr=16000, mono=True)\n",
    "    s_len = len(signal)\n",
    "\n",
    "    # pad the signals to have same size if lesser than required\n",
    "    # else slice them    \n",
    "    \n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(signal, (pad_len, pad_len + pad_rem),\n",
    "                        'constant', constant_values=0)\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len:pad_len + mean_signal_length]\n",
    "        \n",
    "    # sample/frame = mean_signal_length*frame_length\n",
    "    mel_coefficients = mfcc(signal, fs, frame_length=0.048, frame_stride=0.024, num_filters=30, num_cepstral=30, low_frequency=60, high_frequency=7600)\n",
    "    if flatten:\n",
    "        # Flatten the data\n",
    "        mel_coefficients = np.ravel(mel_coefficients)\n",
    "    return mel_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for signal in signals:\n",
    "    features.append(get_feature_vector_from_mfcc(signal, mean_signal_length, flatten=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [-36.04365339,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af4ebfb828>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 152, 30)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to stack these features, so need to add one demenssion\n",
    "features = np.vstack([feature[np.newaxis, :, :] for feature in features])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot code, it is classification not logistic regression, so change numbers to one hot code\n",
    "labels = np_utils.to_categorical(Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 8)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(input_shape[0], input_shape[1])))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='tanh'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(features.shape[1], features.shape[2]), num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 8)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 152, 30)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', \n",
    "                               factor=0.2,\n",
    "                               patience=5,\n",
    "                               min_lr=1e-6,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152 samples, validate on 288 samples\n",
      "Epoch 1/100\n",
      "1152/1152 [==============================] - 10s 9ms/sample - loss: 2.2722 - accuracy: 0.1363 - val_loss: 2.0548 - val_accuracy: 0.1354\n",
      "Epoch 2/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 2.0824 - accuracy: 0.1788 - val_loss: 1.9923 - val_accuracy: 0.2118\n",
      "Epoch 3/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.9788 - accuracy: 0.2361 - val_loss: 1.9676 - val_accuracy: 0.2674\n",
      "Epoch 4/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 1.9126 - accuracy: 0.2743 - val_loss: 1.9170 - val_accuracy: 0.3056\n",
      "Epoch 5/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.7924 - accuracy: 0.3134 - val_loss: 1.6904 - val_accuracy: 0.3924\n",
      "Epoch 6/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.6446 - accuracy: 0.3906 - val_loss: 1.6251 - val_accuracy: 0.4132\n",
      "Epoch 7/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.5394 - accuracy: 0.4470 - val_loss: 1.6332 - val_accuracy: 0.3646\n",
      "Epoch 8/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.4676 - accuracy: 0.4766 - val_loss: 1.5345 - val_accuracy: 0.4375\n",
      "Epoch 9/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.3985 - accuracy: 0.4948 - val_loss: 1.5213 - val_accuracy: 0.4479\n",
      "Epoch 10/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.2657 - accuracy: 0.5720 - val_loss: 1.4928 - val_accuracy: 0.4479\n",
      "Epoch 11/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.1625 - accuracy: 0.5990 - val_loss: 1.4549 - val_accuracy: 0.4653\n",
      "Epoch 12/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 1.1110 - accuracy: 0.6207 - val_loss: 1.3622 - val_accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 1.0077 - accuracy: 0.6658 - val_loss: 1.3978 - val_accuracy: 0.4965\n",
      "Epoch 14/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.9914 - accuracy: 0.6510 - val_loss: 1.2372 - val_accuracy: 0.5694\n",
      "Epoch 15/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.9066 - accuracy: 0.6953 - val_loss: 1.1822 - val_accuracy: 0.5799\n",
      "Epoch 16/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.8683 - accuracy: 0.6997 - val_loss: 1.1777 - val_accuracy: 0.5590\n",
      "Epoch 17/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.7844 - accuracy: 0.7413 - val_loss: 1.1818 - val_accuracy: 0.5556\n",
      "Epoch 18/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.7125 - accuracy: 0.7630 - val_loss: 1.3141 - val_accuracy: 0.5556\n",
      "Epoch 19/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.6746 - accuracy: 0.7821 - val_loss: 1.2053 - val_accuracy: 0.5729\n",
      "Epoch 20/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.6130 - accuracy: 0.8021 - val_loss: 1.2719 - val_accuracy: 0.5729\n",
      "Epoch 21/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.6469 - accuracy: 0.7920\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.6444 - accuracy: 0.7917 - val_loss: 1.2788 - val_accuracy: 0.5972\n",
      "Epoch 22/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.5522 - accuracy: 0.8212 - val_loss: 1.0899 - val_accuracy: 0.6146\n",
      "Epoch 23/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.4576 - accuracy: 0.8568 - val_loss: 1.0519 - val_accuracy: 0.6424\n",
      "Epoch 24/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.4329 - accuracy: 0.8733 - val_loss: 1.0519 - val_accuracy: 0.6424\n",
      "Epoch 25/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.3928 - accuracy: 0.8941 - val_loss: 1.1016 - val_accuracy: 0.6319\n",
      "Epoch 26/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.3761 - accuracy: 0.9002 - val_loss: 1.0902 - val_accuracy: 0.6389\n",
      "Epoch 27/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.3557 - accuracy: 0.8993 - val_loss: 1.1069 - val_accuracy: 0.6632\n",
      "Epoch 28/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.9223\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.3209 - accuracy: 0.9201 - val_loss: 1.1445 - val_accuracy: 0.6076\n",
      "Epoch 29/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.3168 - accuracy: 0.9210 - val_loss: 1.0947 - val_accuracy: 0.6493\n",
      "Epoch 30/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2867 - accuracy: 0.9306 - val_loss: 1.0955 - val_accuracy: 0.6528\n",
      "Epoch 31/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2835 - accuracy: 0.9340 - val_loss: 1.0937 - val_accuracy: 0.6562\n",
      "Epoch 32/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2884 - accuracy: 0.9271 - val_loss: 1.0966 - val_accuracy: 0.6528\n",
      "Epoch 33/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9304\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.2762 - accuracy: 0.9297 - val_loss: 1.0898 - val_accuracy: 0.6597\n",
      "Epoch 34/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2626 - accuracy: 0.9436 - val_loss: 1.0905 - val_accuracy: 0.6562\n",
      "Epoch 35/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2741 - accuracy: 0.9349 - val_loss: 1.0902 - val_accuracy: 0.6562\n",
      "Epoch 36/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2828 - accuracy: 0.9332 - val_loss: 1.0907 - val_accuracy: 0.6562\n",
      "Epoch 37/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2776 - accuracy: 0.9340 - val_loss: 1.0899 - val_accuracy: 0.6562\n",
      "Epoch 38/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9375\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2653 - accuracy: 0.9384 - val_loss: 1.0889 - val_accuracy: 0.6597\n",
      "Epoch 39/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2655 - accuracy: 0.9497 - val_loss: 1.0888 - val_accuracy: 0.6562\n",
      "Epoch 40/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2821 - accuracy: 0.9262 - val_loss: 1.0887 - val_accuracy: 0.6562\n",
      "Epoch 41/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2782 - accuracy: 0.9323 - val_loss: 1.0893 - val_accuracy: 0.6562\n",
      "Epoch 42/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2810 - accuracy: 0.9366 - val_loss: 1.0897 - val_accuracy: 0.6562\n",
      "Epoch 43/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.9321\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2862 - accuracy: 0.9297 - val_loss: 1.0896 - val_accuracy: 0.6562\n",
      "Epoch 44/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2906 - accuracy: 0.9340 - val_loss: 1.0897 - val_accuracy: 0.6562\n",
      "Epoch 45/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2680 - accuracy: 0.9427 - val_loss: 1.0898 - val_accuracy: 0.6562\n",
      "Epoch 46/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2721 - accuracy: 0.9375 - val_loss: 1.0897 - val_accuracy: 0.6562\n",
      "Epoch 47/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2798 - accuracy: 0.9323 - val_loss: 1.0899 - val_accuracy: 0.6562\n",
      "Epoch 48/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2728 - accuracy: 0.9349 - val_loss: 1.0904 - val_accuracy: 0.6562\n",
      "Epoch 49/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2622 - accuracy: 0.9410 - val_loss: 1.0907 - val_accuracy: 0.6562\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2619 - accuracy: 0.9410 - val_loss: 1.0909 - val_accuracy: 0.6562\n",
      "Epoch 51/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2784 - accuracy: 0.9358 - val_loss: 1.0908 - val_accuracy: 0.6562\n",
      "Epoch 52/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2591 - accuracy: 0.9384 - val_loss: 1.0905 - val_accuracy: 0.6562\n",
      "Epoch 53/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2733 - accuracy: 0.9418 - val_loss: 1.0908 - val_accuracy: 0.6562\n",
      "Epoch 54/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2697 - accuracy: 0.9427 - val_loss: 1.0911 - val_accuracy: 0.6562\n",
      "Epoch 55/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2745 - accuracy: 0.9323 - val_loss: 1.0915 - val_accuracy: 0.6562\n",
      "Epoch 56/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2664 - accuracy: 0.9366 - val_loss: 1.0914 - val_accuracy: 0.6562\n",
      "Epoch 57/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2608 - accuracy: 0.9427 - val_loss: 1.0918 - val_accuracy: 0.6562\n",
      "Epoch 58/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2581 - accuracy: 0.9470 - val_loss: 1.0919 - val_accuracy: 0.6562\n",
      "Epoch 59/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2685 - accuracy: 0.9444 - val_loss: 1.0915 - val_accuracy: 0.6562\n",
      "Epoch 60/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2602 - accuracy: 0.9401 - val_loss: 1.0916 - val_accuracy: 0.6562\n",
      "Epoch 61/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2678 - accuracy: 0.9349 - val_loss: 1.0918 - val_accuracy: 0.6562\n",
      "Epoch 62/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2657 - accuracy: 0.9392 - val_loss: 1.0921 - val_accuracy: 0.6562\n",
      "Epoch 63/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2732 - accuracy: 0.9323 - val_loss: 1.0919 - val_accuracy: 0.6562\n",
      "Epoch 64/100\n",
      "1152/1152 [==============================] - 6s 6ms/sample - loss: 0.2695 - accuracy: 0.9418 - val_loss: 1.0922 - val_accuracy: 0.6562\n",
      "Epoch 65/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2722 - accuracy: 0.9418 - val_loss: 1.0920 - val_accuracy: 0.6562\n",
      "Epoch 66/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2681 - accuracy: 0.9418 - val_loss: 1.0919 - val_accuracy: 0.6562\n",
      "Epoch 67/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2813 - accuracy: 0.9271 - val_loss: 1.0919 - val_accuracy: 0.6562\n",
      "Epoch 68/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2771 - accuracy: 0.9332 - val_loss: 1.0919 - val_accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2696 - accuracy: 0.9340 - val_loss: 1.0918 - val_accuracy: 0.6562\n",
      "Epoch 70/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2740 - accuracy: 0.9323 - val_loss: 1.0920 - val_accuracy: 0.6562\n",
      "Epoch 71/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2671 - accuracy: 0.9306 - val_loss: 1.0920 - val_accuracy: 0.6562\n",
      "Epoch 72/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2760 - accuracy: 0.9392 - val_loss: 1.0917 - val_accuracy: 0.6562\n",
      "Epoch 73/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2669 - accuracy: 0.9384 - val_loss: 1.0917 - val_accuracy: 0.6562\n",
      "Epoch 74/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2611 - accuracy: 0.9418 - val_loss: 1.0915 - val_accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2795 - accuracy: 0.9340 - val_loss: 1.0915 - val_accuracy: 0.6562\n",
      "Epoch 76/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2840 - accuracy: 0.9332 - val_loss: 1.0923 - val_accuracy: 0.6562\n",
      "Epoch 77/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2732 - accuracy: 0.9323 - val_loss: 1.0924 - val_accuracy: 0.6562\n",
      "Epoch 78/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2766 - accuracy: 0.9306 - val_loss: 1.0922 - val_accuracy: 0.6562\n",
      "Epoch 79/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2588 - accuracy: 0.9410 - val_loss: 1.0925 - val_accuracy: 0.6562\n",
      "Epoch 80/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2709 - accuracy: 0.9392 - val_loss: 1.0928 - val_accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2670 - accuracy: 0.9392 - val_loss: 1.0926 - val_accuracy: 0.6562\n",
      "Epoch 82/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2582 - accuracy: 0.9462 - val_loss: 1.0933 - val_accuracy: 0.6562\n",
      "Epoch 83/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2695 - accuracy: 0.9306 - val_loss: 1.0930 - val_accuracy: 0.6562\n",
      "Epoch 84/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2821 - accuracy: 0.9323 - val_loss: 1.0932 - val_accuracy: 0.6562\n",
      "Epoch 85/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2733 - accuracy: 0.9349 - val_loss: 1.0933 - val_accuracy: 0.6562\n",
      "Epoch 86/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2632 - accuracy: 0.9418 - val_loss: 1.0935 - val_accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2683 - accuracy: 0.9358 - val_loss: 1.0933 - val_accuracy: 0.6562\n",
      "Epoch 88/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2633 - accuracy: 0.9418 - val_loss: 1.0935 - val_accuracy: 0.6562\n",
      "Epoch 89/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2691 - accuracy: 0.9444 - val_loss: 1.0935 - val_accuracy: 0.6562\n",
      "Epoch 90/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2633 - accuracy: 0.9418 - val_loss: 1.0931 - val_accuracy: 0.6562\n",
      "Epoch 91/100\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.2735 - accuracy: 0.9332 - val_loss: 1.0932 - val_accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.2562 - accuracy: 0.9418 - val_loss: 1.0933 - val_accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2575 - accuracy: 0.9470 - val_loss: 1.0930 - val_accuracy: 0.6562\n",
      "Epoch 94/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2716 - accuracy: 0.9375 - val_loss: 1.0930 - val_accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2613 - accuracy: 0.9375 - val_loss: 1.0931 - val_accuracy: 0.6562\n",
      "Epoch 96/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2632 - accuracy: 0.9401 - val_loss: 1.0931 - val_accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "1152/1152 [==============================] - 7s 6ms/sample - loss: 0.2626 - accuracy: 0.9427 - val_loss: 1.0931 - val_accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2692 - accuracy: 0.9375 - val_loss: 1.0932 - val_accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2567 - accuracy: 0.9462 - val_loss: 1.0927 - val_accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "1152/1152 [==============================] - 6s 5ms/sample - loss: 0.2684 - accuracy: 0.9392 - val_loss: 1.0926 - val_accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=34, validation_data=(x_test, y_test), callbacks=[lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
