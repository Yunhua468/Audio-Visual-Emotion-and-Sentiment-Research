{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.io.wavfile as wav\n",
    "from speechpy.feature import mfcc\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = 'C:\\\\Users\\\\ZhaoY\\\\Downloads\\\\DL_Project\\\\dataset\\\\Audio_Speech_Actors_01-24\\\\'\n",
    "dir_list = os.listdir(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Audio_Speech_Actors_01-24\\ hahaha\n"
     ]
    }
   ],
   "source": [
    "#get the paths\n",
    "dirts = []\n",
    "filepath_delete = True\n",
    "for root, dirt,file in os.walk(FILEPATH):\n",
    "    if filepath_delete == True:\n",
    "        print(root, \"hahaha\")\n",
    "        filepath_delete = False\n",
    "    else:\n",
    "        dirts.append(root)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the files in every path\n",
    "files = []\n",
    "for dirt in dirts:\n",
    "    for root, dt, file in os.walk(dirt):\n",
    "        for fl in file:\n",
    "            files.append(os.path.join(dirt,fl))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ZhaoY\\\\Downloads\\\\DL_Project\\\\dataset\\\\Audio_Speech_Actors_01-24\\\\Actor_01\\\\03-01-01-01-01-02-01.wav'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = []\n",
    "Actor = []\n",
    "for file in files:\n",
    "    filename.append(file.split('\\\\')[-1])\n",
    "    Actor.append(file.split('\\\\')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-01-01-01-01-01.wav'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actor_24'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actor[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modality = []\n",
    "Vocal_channel = []\n",
    "Emotion = []\n",
    "Emotional_intensity = []\n",
    "Statement = []\n",
    "Repetition = []\n",
    "\n",
    "for name in filename:\n",
    "    Modality.append(name.split('-')[0])\n",
    "    Vocal_channel.append(name.split('-')[1])\n",
    "    Emotion.append(name.split('-')[2])\n",
    "    Emotional_intensity.append(name.split('-')[3])\n",
    "    Statement.append(name.split('-')[4])\n",
    "    Repetition.append(name.split('-')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'files': files, \n",
    "                   'modalities': Modality,\n",
    "                   'vocal_channels': Vocal_channel, \n",
    "                   'emotions': Emotion,\n",
    "                   'emotional_intensities': Emotional_intensity,\n",
    "                   'statements': Statement,\n",
    "                   'repetitiona': Repetition})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>modalities</th>\n",
       "      <th>vocal_channels</th>\n",
       "      <th>emotions</th>\n",
       "      <th>emotional_intensities</th>\n",
       "      <th>statements</th>\n",
       "      <th>repetitiona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Au...</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               files modalities  \\\n",
       "0  C:\\Users\\ZhaoY\\Downloads\\DL_Project\\dataset\\Au...         03   \n",
       "\n",
       "  vocal_channels emotions emotional_intensities statements repetitiona  \n",
       "0             01       01                    01         01          01  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1440 entries, 0 to 1439\n",
      "Data columns (total 7 columns):\n",
      "files                    1440 non-null object\n",
      "modalities               1440 non-null object\n",
      "vocal_channels           1440 non-null object\n",
      "emotions                 1440 non-null object\n",
      "emotional_intensities    1440 non-null object\n",
      "statements               1440 non-null object\n",
      "repetitiona              1440 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03    192\n",
       "02    192\n",
       "08    192\n",
       "06    192\n",
       "04    192\n",
       "05    192\n",
       "07    192\n",
       "01     96\n",
       "Name: emotions, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_signal_length = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector_from_mfcc(file_path: str, flatten: bool, mfcc_len: int = 39) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make feature vector from MFCC for the given wav file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): path to the .wav file that needs to be read.\n",
    "        flatten (bool) : Boolean indicating whether to flatten mfcc obtained.\n",
    "        mfcc_len (int): Number of cepestral co efficients to be consider.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: feature vector of the wav file made from mfcc.\n",
    "    \"\"\"\n",
    "    #fs, signal = wav.read(file_path)\n",
    "    signal, fs = librosa.load(file_path, sr=16000, mono=True)\n",
    "    s_len = len(signal)\n",
    "    # pad the signals to have same size if lesser than required\n",
    "    # else slice them\n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(signal, (pad_len, pad_len + pad_rem),\n",
    "                        'constant', constant_values=0)\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len:pad_len + mean_signal_length]\n",
    "    mel_coefficients = mfcc(signal, fs, frame_length=0.048, frame_stride=0.024, num_filters=30, num_cepstral=30, low_frequency=60, high_frequency=7600)\n",
    "    if flatten:\n",
    "        # Flatten the data\n",
    "        mel_coefficients = np.ravel(mel_coefficients)\n",
    "    return mel_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for fname in files:\n",
    "    features.append(get_feature_vector_from_mfcc(file_path=fname, flatten=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-23.0579412 ,  -3.88776846,   0.90846602, ...,  -0.70632757,\n",
       "         -0.08511071,  -0.08972508],\n",
       "       [-19.67914709,   1.21891113,   3.58783623, ...,  -0.28147429,\n",
       "          0.14504516,  -0.05287299],\n",
       "       [-21.57244746,  -3.02955937,   1.40766177, ...,  -0.33779273,\n",
       "         -0.62083518,  -0.62510661],\n",
       "       ...,\n",
       "       [-16.96064188,   4.63580318,   1.75827104, ...,  -0.798592  ,\n",
       "         -0.26239699,  -0.28730119],\n",
       "       [-16.31052999,   4.20401261,   1.53438623, ...,  -0.42121078,\n",
       "         -0.61865751,  -0.76526708],\n",
       "       [-17.48487525,   1.26741618,   0.40775745, ...,   0.25475895,\n",
       "         -0.4278531 ,  -0.67127583]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af1e759898>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 81, 30)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.vstack([feature[np.newaxis, :, :] for feature in features])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np_utils.to_categorical(Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(input_shape[0], input_shape[1])))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='tanh'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(81, 30), num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', \n",
    "                               factor=0.2,\n",
    "                               patience=5,\n",
    "                               min_lr=1e-6,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (1152, 9) was passed for an output of shape (None, 8) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-46e0610e6660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2536\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2538\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    742\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (1152, 9) was passed for an output of shape (None, 8) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "# hist = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), callbacks=[lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
