{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearningVggish.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYd3hHcU3HZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://zenodo.org/api/files/c8f9b6fe-82ac-481c-ad9c-12b5581cb4b4/Audio_Song_Actors_01-24.zip\n",
        "!wget https://zenodo.org/api/files/c8f9b6fe-82ac-481c-ad9c-12b5581cb4b4/Audio_Speech_Actors_01-24.zip\n",
        "\n",
        "!unzip -q -d ./song Audio_Song_Actors_01-24.zip \n",
        "!unzip -q -d ./speech Audio_Speech_Actors_01-24.zip \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSbSeXk43OP3",
        "colab_type": "text"
      },
      "source": [
        "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "\n",
        "Vocal channel (01 = speech, 02 = song).\n",
        "\n",
        "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "\n",
        "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "\n",
        "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "\n",
        "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "\n",
        "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUf4FwvSuj8Z",
        "colab_type": "text"
      },
      "source": [
        "### here you need to download files from github repo, I did not add it since I sync my local to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zb2qOlz_f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q Audio-Visual-Emotion-and-Sentiment-Research-audio.zip\n",
        "!mv Audio-Visual-Emotion-and-Sentiment-Research-audio ./Audio-Visual-Emotion-and-Sentiment-Research/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8r99PzuZkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %% codecell\n",
        "#  pydub is required and not in colab already\n",
        "!pip install soundfile\n",
        "# %% codecell\n",
        "# get model files and place in assets folder\n",
        "!wget https://max-assets-prod.s3.us-south.cloud-object-storage.appdomain.cloud/max-audio-classifier/1.0.0/assets.tar.gz\n",
        "!tar -xzvf assets.tar.gz\n",
        "!mv classifier_model.h5 ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n",
        "!mv vggish_pca_params.npz ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n",
        "!mv vggish_model.ckpt ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mutkoRT9YrlT",
        "colab_type": "code",
        "outputId": "b0f4bcf3-efb1-4ff6-cf4e-6cfe3a0f663b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# %cd ./Audio-Visual-Emotion-and-Sentiment-Research/\n",
        "import os\n",
        "import sys\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('./Audio-Visual-Emotion-and-Sentiment-Research/Scripts'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Audio-Visual-Emotion-and-Sentiment-Research\n",
            "/content/Audio-Visual-Emotion-and-Sentiment-Research/Scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz68sxjjwfSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9a92c1c-be87-4de5-ffab-be09652cc7c4"
      },
      "source": [
        "# %% codecell\n",
        "import tensorflow as tf\n",
        "from models_api import VggishModelWrapper\n",
        "import pre_process_func\n",
        "\n",
        "Vgg=VggishModelWrapper()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from assets/vggish_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5Jpeuslq6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "file_list=glob.glob(\"./speech/**/*.wav\")+glob.glob(\"./song/**/*.wav\")\n",
        "\n",
        "raw={}\n",
        "post={}\n",
        "for wavFile in file_list:\n",
        "\n",
        "    sound = pre_process_func.pre_process(wavFile)\n",
        "    raw_embeddings,post_processed_embed =Vgg.generate_embeddings(sound)\n",
        "    filename=wavFile.split(\"/\")[-1]\n",
        "    raw[filename]=raw_embeddings\n",
        "    post[filename]=post_processed_embed\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCufMjyL7_Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Klqlly2r5EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "embeddings={\"raw\":raw,\"post\":post}\n",
        "\n",
        "with open('embeddings.dat', 'wb') as outfile:\n",
        "    pickle.dump(embeddings, outfile, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is8UHE__y68h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('embeddings.dat', 'rb') as file:\n",
        "    embeddings=pickle.load(file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPcfDAaHy_3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDgWA-s-zIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}