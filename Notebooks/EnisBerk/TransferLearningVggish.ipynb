{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYd3hHcU3HZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://zenodo.org/api/files/c8f9b6fe-82ac-481c-ad9c-12b5581cb4b4/Audio_Song_Actors_01-24.zip\n",
        "\n",
        "!mkdir unzipped\n",
        "!unzip -q -d ./unzipped Audio_Song_Actors_01-24.zip \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSbSeXk43OP3",
        "colab_type": "text"
      },
      "source": [
        "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "\n",
        "Vocal channel (01 = speech, 02 = song).\n",
        "\n",
        "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "\n",
        "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "\n",
        "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "\n",
        "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "\n",
        "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8r99PzuZkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %% codecell\n",
        "#  pydub is required and not in colab already\n",
        "!pip install soundfile\n",
        "# %% codecell\n",
        "# get model files and place in assets folder\n",
        "!wget https://max-assets-prod.s3.us-south.cloud-object-storage.appdomain.cloud/max-audio-classifier/1.0.0/assets.tar.gz\n",
        "!tar -xzvf assets.tar.gz\n",
        "!mv classifier_model.h5 ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n",
        "!mv vggish_pca_params.npz ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n",
        "!mv vggish_model.ckpt ./Audio-Visual-Emotion-and-Sentiment-Research/assets/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUf4FwvSuj8Z",
        "colab_type": "text"
      },
      "source": [
        "### here you need to download files from github repo, I did not add it since I sync my local to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mutkoRT9YrlT",
        "colab_type": "code",
        "outputId": "aa940052-a0e8-4501-cde0-7ad2f26aaa0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "%cd ./Audio-Visual-Emotion-and-Sentiment-Research/\n",
        "import os\n",
        "import sys\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('./Scripts'))\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "/content/Audio-Visual-Emotion-and-Sentiment-Research\n",
            "/content/Audio-Visual-Emotion-and-Sentiment-Research/Scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz68sxjjwfSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% codecell\n",
        "import tensorflow as tf\n",
        "from models_api import VggishModelWrapper\n",
        "import pre_process_func\n",
        "\n",
        "Vgg=VggishModelWrapper()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5Jpeuslq6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAV=\"../unzipped/\"\n",
        "import os\n",
        "\n",
        "dir_list = os.listdir(RAV)\n",
        "dir_list.sort()\n",
        "\n",
        "\n",
        "raw={}\n",
        "post={}\n",
        "for i in dir_list:\n",
        "    fname = os.listdir(RAV + i)\n",
        "    for f in fname:\n",
        "        wavFile=RAV+i+\"/\"+f\n",
        "        sound = pre_process_func.pre_process(wavFile)\n",
        "        raw_embeddings,post_processed_embed =Vgg.generate_embeddings(sound)\n",
        "        filename=(i+\"/\"+f)\n",
        "        raw[filename]=raw_embeddings\n",
        "        post[filename]=post_processed_embed\n",
        "        \n",
        "    print(i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Klqlly2r5EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "embeddings={\"raw\":raw,\"post\":post}\n",
        "\n",
        "with open('embeddings.dat', 'wb') as outfile:\n",
        "    pickle.dump(embeddings, outfile, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}