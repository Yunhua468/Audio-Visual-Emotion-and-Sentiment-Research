{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwoInputOneModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38QSEONVeAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/6s06zacfu9jn4z8/Patrick%20Jean-Baptiste%20-%20Emotion_Image_Data_Modified.zip?dl=1 -O Emotion_Images.zip\n",
        "\n",
        "!wget -q https://zenodo.org/api/files/c8f9b6fe-82ac-481c-ad9c-12b5581cb4b4/Audio_Song_Actors_01-24.zip\n",
        "!wget -q https://zenodo.org/api/files/c8f9b6fe-82ac-481c-ad9c-12b5581cb4b4/Audio_Speech_Actors_01-24.zip\n",
        "\n",
        "!unzip -q -d ./song Audio_Song_Actors_01-24.zip \n",
        "!unzip -q -d ./speech Audio_Speech_Actors_01-24.zip\n",
        "!unzip -q Emotion_Images.zip\n",
        "\n",
        "!wget -q https://www.dropbox.com/s/yigijs122togfk4/embeddings.dat?dl=1  -O embeddings.dat\n",
        "!wget -q https://www.dropbox.com/s/qdhtexle4p0ngc3/DatasetSplitCSV.zip?dl=1 -O DatasetSplitCSV.zip\n",
        "!unzip -q DatasetSplitCSV.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSRpuN18WMUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df14980a-f972-4c63-f862-776507bb2f58"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import glob\n",
        "\n",
        "# example of converting an image with the Keras API\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5jQWITnV7Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapReduce(embed,funcName):\n",
        "    if funcName==\"Avg\":\n",
        "        embed= [np.average(embed,axis=0)]\n",
        "    if funcName==\"Pad\":\n",
        "        embed=np.pad(embed, [( 0,6-embed.shape[0]), (0, 0)], mode='constant', constant_values=0)\n",
        "        embed= [embed.reshape(-1)]\n",
        "    if funcName==\"Many2One\":\n",
        "        embed=[embed[i,:] for i in range(embed.shape[0])]\n",
        "    if funcName==\"None\":\n",
        "        embed=[embed]\n",
        "    return embed\n",
        "\n",
        "def uint8_to_float32(x):\n",
        "    return (np.float32(x) - 128.) / 128."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrOVV8edWRBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters\n",
        "params={}\n",
        "params[\"embeddingType\"]=\"post\" # post,raw\n",
        "params[\"mapReduceFunc\"]=\"Pad\" # Avg,Pad,Many2One"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVHG478AWIZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(\"train.csv\",header=None)\n",
        "valid=pd.read_csv(\"valid.csv\",header=None)\n",
        "test=pd.read_csv(\"test.csv\",header=None)\n",
        "\n",
        "embeddings=np.load(\"embeddings.dat\",allow_pickle=True)\n",
        "# embeddings[\"post\"]['03-02-04-01-02-02-02.wav'].dtype\n",
        "seconds={}\n",
        "\n",
        "for df in [train,test,valid]:\n",
        "    for i in df.index:\n",
        "        df.at[i, 0] = df.iloc[i][0][3:]\n",
        "\n",
        "embeddings2={\"post\":{}}\n",
        "for key,embed in embeddings[\"post\"].items():\n",
        "    embeddings2[\"post\"][key[3:]]=embed\n",
        "embeddings=embeddings2\n",
        "\n",
        "for key,embed in embeddings[\"post\"].items():\n",
        "    embeddings[\"post\"][key]=uint8_to_float32(embed)\n",
        "    seconds[key]=embed.shape[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqewJ6bVWKJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=[]\n",
        "x_val=[]\n",
        "x_test=[]\n",
        "for x in train[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_train.extend(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "for x in valid[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_val.extend(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "for x in test[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_test.extend(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "x_train=np.array(x_train)\n",
        "x_val=np.array(x_val)\n",
        "x_test=np.array(x_test)\n",
        "\n",
        "y_train=np.array(train[1].astype('category').cat.codes)\n",
        "y_val=np.array(valid[1].astype('category').cat.codes)\n",
        "y_test=np.array(test[1].astype('category').cat.codes)\n",
        "\n",
        "if params[\"mapReduceFunc\"]==\"Many2One\":\n",
        "    # print(\"a\")\n",
        "    y_train2,y_val2,y_test2=[],[],[]\n",
        "    for x,y,y2 in zip([train[0],valid[0],test[0]],[y_train,y_val,y_test],[y_train2,y_val2,y_test2]):\n",
        "        for i,embedName in enumerate(x):\n",
        "            # print(seconds[embedName])\n",
        "            y2.extend([y[i] for k in range(seconds[embedName])])\n",
        "        # print(y2)\n",
        "    y_train,y_val,y_test=[np.array(y) for y in [y_train2,y_val2,y_test2]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSbHupJD6z6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00a7ee0f-a7d0-46e8-ce30-1ddecb16e00e"
      },
      "source": [
        "len(imageList),len(x_train)+len(x_val)+len(x_test)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4902, 2452)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNXUaDA1Wbbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageList=glob.glob(\"Emotion_Image_Data_Modified/Emotion_Images/*\")\n",
        "imageDict={}\n",
        "for img in imageList:\n",
        "    fname=(img).split(\"/\")[-1].split(\".\")[0]+\".wav\"\n",
        "    fname=fname[3:]\n",
        "    imageDict.setdefault(fname,[])\n",
        "    imageDict[fname].append(img)\n",
        "\n",
        "for k,v in imageDict.items():\n",
        "    if len(v)<2:\n",
        "        imageDict[k].append(v[0])\n",
        "        # print(k)\n",
        "    v[0] = img_to_array(load_img(v[0]))\n",
        "    v[1] = img_to_array(load_img(v[1]))\n",
        "    # imageDict[k]=np.concatenate(v,axis=0)\n",
        "    imageDict[k]=v[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKndRLAE-pIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOQBq9tBZNw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "x_trainImg=[]\n",
        "x_valImg=[]\n",
        "x_testImg=[]\n",
        "for x in train[0]:\n",
        "    image=[imageDict[k]]\n",
        "    x_trainImg.extend(image)\n",
        "\n",
        "\n",
        "for x in valid[0]:\n",
        "    image=[imageDict[k]]\n",
        "    x_valImg.extend(image)\n",
        "\n",
        "for x in test[0]:\n",
        "    image=[imageDict[k]]\n",
        "    x_testImg.extend(image)\n",
        "\n",
        "x_trainImg=np.array(x_trainImg)\n",
        "x_valImg=np.array(x_valImg)\n",
        "x_testImg=np.array(x_testImg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVEC9Y327d3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdCPyAhNamiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from __future__ import print_function\n",
        "# import keras\n",
        "# from keras.datasets import mnist\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras import backend as K\n",
        "\n",
        "\n",
        "# batch_size = 128\n",
        "# num_classes = 10\n",
        "# epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "# img_rows, img_cols = 256, 128\n",
        "\n",
        "# the data, split between train and test sets\n",
        "\n",
        "# if K.image_data_format() == 'channels_first':\n",
        "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "#     input_shape = (1, img_rows, img_cols)\n",
        "# else:\n",
        "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "#     input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# x_train /= 255\n",
        "# x_test /= 255\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# # convert class vectors to binary class matrices\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "#                  activation='relu',\n",
        "#                  input_shape=input_shape))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#           validation_data=(x_test, y_test))\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ope8yZIq63XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "428293c6-1c19-4487-d0c4-ae695890b7ee"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n5ZQy_Q65ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58372cb8-dae8-44bd-b2ff-b9f35bd0da25"
      },
      "source": [
        "# inputs = keras.Input(shape=(x_train.shape[-1],), name=\"log-mel\")\n",
        "# x = tf.keras.layers.Reshape((1, 128), input_shape=(x_train.shape[-1],))(inputs)\n",
        "# x = layers.LSTM(128,input_shape=((1,128)))(x)\n",
        "# # x = layers.Dense(128, activation=\"tanh\", name=\"dense_1\")(inputs)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(64, activation=\"tanh\", name=\"dense_2\")(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(32, activation=\"tanh\", name=\"dense_3\")(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# outputs = layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "# model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'channels_last'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zBnPSj7QZE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e2fcd98-95cf-495e-f256-d66fee5d9a08"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1470, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSUWWH48qeDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(x_train.shape[-1],), name=\"log-mel\")\n",
        "# x = tf.keras.layers.Reshape((1, 128), input_shape=(x_train.shape[-1],))(inputs)\n",
        "# x = layers.LSTM(128,input_shape=((1,128)))(x)\n",
        "x = layers.Dense(128, activation=\"tanh\", name=\"dense_1\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation=\"tanh\", name=\"dense_2\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(32, activation=\"tanh\", name=\"dense_3\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs2 = layers.Dense(8, activation=\"relu\")(x)\n",
        "\n",
        "model2 = keras.Model(inputs=inputs, outputs=outputs2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAsUc04EPbNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VInputs = keras.Input(shape=(256,128,3), name=\"images\")\n",
        "v=layers.Conv2D(32, 3,activation='relu' )(VInputs)\n",
        "v=layers.Conv2D(64, 3, activation='relu')(v)\n",
        "v=layers.MaxPooling2D(pool_size=(2, 2))(v)\n",
        "v=layers.Dropout(0.25)(v)\n",
        "v=layers.Flatten()(v)\n",
        "v=layers.Dense(128, activation='relu')(v)\n",
        "v=layers.Dense(8, activation='relu')(v)\n",
        "output=layers.Dropout(0.25)(v)\n",
        "\n",
        "model1 = keras.Model(inputs=VInputs, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjFmj-GtPTCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergedOut = layers.Add()([model1.output,model2.output])\n",
        "mergedOut=layers.Dense(8, activation='softmax')(mergedOut)\n",
        "\n",
        "\n",
        "newModel = keras.Model([model1.input,model2.input], mergedOut)\n",
        "newModel.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK88y_ht7Af8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
        "                               factor=0.2,\n",
        "                               patience=5,\n",
        "                               min_lr=1e-6,\n",
        "                               verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23d9Y8lMrxn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_callbacks=[lr_reducer,\n",
        "              tf.keras.callbacks.EarlyStopping(patience=50),\n",
        "              tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM7Fein5Cn7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "97e55383-6837-456c-9834-7b0e046b8380"
      },
      "source": [
        "newModel.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             [(None, 256, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "log-mel (InputLayer)            [(None, 768)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 254, 126, 32) 896         images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          98432       log-mel[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 252, 124, 64) 18496       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 126, 62, 64)  0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 128)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 126, 62, 64)  0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 499968)       0           dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 64)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 128)          63996032    flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           2080        dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 8)            1032        dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 32)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8)            0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 8)            264         dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8)            0           dropout_27[0][0]                 \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 8)            72          add_9[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 64,126,072\n",
            "Trainable params: 64,125,816\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOfcLImCyqYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}