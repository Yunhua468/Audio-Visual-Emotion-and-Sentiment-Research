{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepModelOnEmbeds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6RwK8svuJIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/yigijs122togfk4/embeddings.dat?dl=1  -O embeddings.dat\n",
        "!wget -q https://www.dropbox.com/s/qdhtexle4p0ngc3/DatasetSplitCSV.zip?dl=1 -O DatasetSplitCSV.zip\n",
        "!unzip -q DatasetSplitCSV.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsEWFA6FxQIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH-eHmId4xnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters\n",
        "params={}\n",
        "params[\"embeddingType\"]=\"raw\" # post\n",
        "params[\"mapReduceFunc\"]=\"Pad\" # Avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFRTlNWn5iQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapReduce(embed,funcName):\n",
        "    if funcName==\"Avg\":\n",
        "        embed=np.average(embed,axis=0)\n",
        "    if funcName==\"Pad\":\n",
        "        embed=np.pad(embed, [( 0,6-embed.shape[0]), (0, 0)], mode='constant', constant_values=0)\n",
        "        embed=embed.reshape(-1)\n",
        "    return embed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG1dWgiWyYNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(\"train.csv\",header=None)\n",
        "valid=pd.read_csv(\"valid.csv\",header=None)\n",
        "test=pd.read_csv(\"test.csv\",header=None)\n",
        "embeddings=np.load(\"embeddings.dat\",allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iZSfQst6Zma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b21e603b-7c91-4bb8-d0da-2ed0f306b7f4"
      },
      "source": [
        "embeddings[\"post\"]['03-02-04-01-02-02-02.wav'].dtype"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9NdkXAKz9ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8b5ecca-5710-4447-92e9-f3e386f5d72e"
      },
      "source": [
        "list(embeddings['raw'].keys())[2000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'03-02-04-01-02-02-02.wav'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvSFF0cO6k_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test=[]\n",
        "# for x in train[0]:\n",
        "#     embed=embeddings[params[\"embeddingType\"]][x]\n",
        "\n",
        "#     test.append(embed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nBsi7LAYuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.array(test).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3HB0HEkLKbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOK9U8SvKFvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8668ad45-8c0b-4099-cb7e-de444d21f72d"
      },
      "source": [
        "# test[0].s"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8c3c430d41be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 's'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ck1lGA3Ae2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padded_inputs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk-TFWQn4fMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=[]\n",
        "x_val=[]\n",
        "x_test=[]\n",
        "for x in train[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_train.append(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "for x in valid[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_val.append(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "for x in test[0]:\n",
        "    embed=embeddings[params[\"embeddingType\"]][x]\n",
        "    x_test.append(mapReduce(embed,params[\"mapReduceFunc\"]))\n",
        "\n",
        "x_train=np.array(x_train)\n",
        "x_val=np.array(x_val)\n",
        "x_test=np.array(x_test)\n",
        "\n",
        "y_train=np.array(train[1].astype('category').cat.codes)\n",
        "y_val=np.array(valid[1].astype('category').cat.codes)\n",
        "y_test=np.array(test[1].astype('category').cat.codes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nb2Mjtm2Ag2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import Counter\n",
        "# shapes=[]\n",
        "# for f,embed in embeddings['raw'].items():\n",
        "#     shapes.append((embed.shape))\n",
        "# Counter(shapes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0VYELFD19J2",
        "colab_type": "text"
      },
      "source": [
        "Average Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvD1H2GgMmGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(x_train.shape[-1],), name=\"log-mel\")\n",
        "# x = tf.keras.layers.Reshape((6, 128), input_shape=(x_train.shape[-1],))(inputs)\n",
        "# x = layers.LSTM(128,input_shape=((6,128)))(x)\n",
        "x = layers.Dense(64, activation=\"tanh\", name=\"dense_1\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation=\"tanh\", name=\"dense_2\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(32, activation=\"tanh\", name=\"dense_3\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X_PMIBB0GO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs = keras.Input(shape=(x_train.shape[-1],), name=\"log-mel\")\n",
        "# x = tf.keras.layers.Reshape((6, 128), input_shape=(x_train.shape[-1],))(inputs)\n",
        "# x = layers.LSTM(128,input_shape=((6,128)))(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(64, activation=\"tanh\", name=\"dense_1\")(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(32, activation=\"tanh\", name=\"dense_2\")(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# outputs = layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "# model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN0eGUGY9fuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # model.add(layers.LSTM(128, input_shape=(input_shape[0], input_shape[1])))\n",
        "    # model.add(layers.BatchNormalization())\n",
        "    # model.add(layers.Dropout(0.5))\n",
        "    # model.add(layers.Dense(32, activation='relu'))\n",
        "    # model.add(layers.Dense(16, activation='tanh'))\n",
        "    # model.add(layers.Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "creytJIn8df9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfcc9fdf-83ba-4fba-83ef-b96f8deb5201"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "print('# Fit model on training data')\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=200,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n",
        "print('\\nhistory dict:', history.history)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Fit model on training data\n",
            "Epoch 1/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 2.0730 - sparse_categorical_accuracy: 0.1415 - val_loss: 2.0417 - val_sparse_categorical_accuracy: 0.3035\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0363 - sparse_categorical_accuracy: 0.2136 - val_loss: 1.9938 - val_sparse_categorical_accuracy: 0.2994\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0164 - sparse_categorical_accuracy: 0.2442 - val_loss: 1.9568 - val_sparse_categorical_accuracy: 0.3136\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9800 - sparse_categorical_accuracy: 0.2925 - val_loss: 1.9345 - val_sparse_categorical_accuracy: 0.3259\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9601 - sparse_categorical_accuracy: 0.3170 - val_loss: 1.9199 - val_sparse_categorical_accuracy: 0.3360\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9451 - sparse_categorical_accuracy: 0.3340 - val_loss: 1.9037 - val_sparse_categorical_accuracy: 0.3483\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9332 - sparse_categorical_accuracy: 0.3388 - val_loss: 1.8903 - val_sparse_categorical_accuracy: 0.3747\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9315 - sparse_categorical_accuracy: 0.3497 - val_loss: 1.8802 - val_sparse_categorical_accuracy: 0.3768\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9110 - sparse_categorical_accuracy: 0.3680 - val_loss: 1.8740 - val_sparse_categorical_accuracy: 0.3890\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8982 - sparse_categorical_accuracy: 0.3776 - val_loss: 1.8599 - val_sparse_categorical_accuracy: 0.4073\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9039 - sparse_categorical_accuracy: 0.3741 - val_loss: 1.8483 - val_sparse_categorical_accuracy: 0.4236\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8839 - sparse_categorical_accuracy: 0.4000 - val_loss: 1.8425 - val_sparse_categorical_accuracy: 0.4216\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8808 - sparse_categorical_accuracy: 0.3966 - val_loss: 1.8365 - val_sparse_categorical_accuracy: 0.4358\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8655 - sparse_categorical_accuracy: 0.4143 - val_loss: 1.8295 - val_sparse_categorical_accuracy: 0.4399\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8611 - sparse_categorical_accuracy: 0.4231 - val_loss: 1.8293 - val_sparse_categorical_accuracy: 0.4338\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8576 - sparse_categorical_accuracy: 0.4204 - val_loss: 1.8223 - val_sparse_categorical_accuracy: 0.4644\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8470 - sparse_categorical_accuracy: 0.4333 - val_loss: 1.8252 - val_sparse_categorical_accuracy: 0.4542\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8312 - sparse_categorical_accuracy: 0.4544 - val_loss: 1.8244 - val_sparse_categorical_accuracy: 0.4460\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8245 - sparse_categorical_accuracy: 0.4633 - val_loss: 1.8146 - val_sparse_categorical_accuracy: 0.4582\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8308 - sparse_categorical_accuracy: 0.4524 - val_loss: 1.8126 - val_sparse_categorical_accuracy: 0.4664\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8197 - sparse_categorical_accuracy: 0.4701 - val_loss: 1.8058 - val_sparse_categorical_accuracy: 0.4827\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8200 - sparse_categorical_accuracy: 0.4639 - val_loss: 1.8030 - val_sparse_categorical_accuracy: 0.4705\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7986 - sparse_categorical_accuracy: 0.4918 - val_loss: 1.8024 - val_sparse_categorical_accuracy: 0.4684\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8000 - sparse_categorical_accuracy: 0.4816 - val_loss: 1.7933 - val_sparse_categorical_accuracy: 0.4847\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7946 - sparse_categorical_accuracy: 0.4864 - val_loss: 1.8053 - val_sparse_categorical_accuracy: 0.4542\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7788 - sparse_categorical_accuracy: 0.5048 - val_loss: 1.7885 - val_sparse_categorical_accuracy: 0.4888\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7803 - sparse_categorical_accuracy: 0.4986 - val_loss: 1.7900 - val_sparse_categorical_accuracy: 0.4786\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7934 - sparse_categorical_accuracy: 0.4925 - val_loss: 1.7793 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7731 - sparse_categorical_accuracy: 0.5109 - val_loss: 1.7762 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7704 - sparse_categorical_accuracy: 0.5082 - val_loss: 1.7890 - val_sparse_categorical_accuracy: 0.4827\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7670 - sparse_categorical_accuracy: 0.5204 - val_loss: 1.7744 - val_sparse_categorical_accuracy: 0.4969\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7590 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.7795 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7565 - sparse_categorical_accuracy: 0.5327 - val_loss: 1.7602 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7548 - sparse_categorical_accuracy: 0.5320 - val_loss: 1.7635 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7547 - sparse_categorical_accuracy: 0.5238 - val_loss: 1.7688 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7402 - sparse_categorical_accuracy: 0.5565 - val_loss: 1.7693 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7471 - sparse_categorical_accuracy: 0.5381 - val_loss: 1.7679 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7171 - sparse_categorical_accuracy: 0.5762 - val_loss: 1.7600 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7280 - sparse_categorical_accuracy: 0.5571 - val_loss: 1.7767 - val_sparse_categorical_accuracy: 0.4908\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7251 - sparse_categorical_accuracy: 0.5537 - val_loss: 1.7729 - val_sparse_categorical_accuracy: 0.4949\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7417 - sparse_categorical_accuracy: 0.5401 - val_loss: 1.7709 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7208 - sparse_categorical_accuracy: 0.5667 - val_loss: 1.7715 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7069 - sparse_categorical_accuracy: 0.5830 - val_loss: 1.7638 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7156 - sparse_categorical_accuracy: 0.5694 - val_loss: 1.7651 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7124 - sparse_categorical_accuracy: 0.5680 - val_loss: 1.7768 - val_sparse_categorical_accuracy: 0.4807\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6992 - sparse_categorical_accuracy: 0.5898 - val_loss: 1.7723 - val_sparse_categorical_accuracy: 0.4868\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6981 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.7721 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7078 - sparse_categorical_accuracy: 0.5769 - val_loss: 1.7644 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7048 - sparse_categorical_accuracy: 0.5803 - val_loss: 1.7661 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6854 - sparse_categorical_accuracy: 0.5986 - val_loss: 1.7709 - val_sparse_categorical_accuracy: 0.4969\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6943 - sparse_categorical_accuracy: 0.5823 - val_loss: 1.7549 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6881 - sparse_categorical_accuracy: 0.5912 - val_loss: 1.7497 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6817 - sparse_categorical_accuracy: 0.6048 - val_loss: 1.7471 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6903 - sparse_categorical_accuracy: 0.5952 - val_loss: 1.7452 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6748 - sparse_categorical_accuracy: 0.6109 - val_loss: 1.7490 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6777 - sparse_categorical_accuracy: 0.6027 - val_loss: 1.7549 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6755 - sparse_categorical_accuracy: 0.6129 - val_loss: 1.7457 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6716 - sparse_categorical_accuracy: 0.6129 - val_loss: 1.7425 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6686 - sparse_categorical_accuracy: 0.6163 - val_loss: 1.7489 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6700 - sparse_categorical_accuracy: 0.6109 - val_loss: 1.7531 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6688 - sparse_categorical_accuracy: 0.6116 - val_loss: 1.7493 - val_sparse_categorical_accuracy: 0.5295\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6610 - sparse_categorical_accuracy: 0.6204 - val_loss: 1.7522 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6610 - sparse_categorical_accuracy: 0.6252 - val_loss: 1.7613 - val_sparse_categorical_accuracy: 0.4969\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6613 - sparse_categorical_accuracy: 0.6218 - val_loss: 1.7536 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6573 - sparse_categorical_accuracy: 0.6245 - val_loss: 1.7457 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6618 - sparse_categorical_accuracy: 0.6211 - val_loss: 1.7484 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6582 - sparse_categorical_accuracy: 0.6204 - val_loss: 1.7388 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6515 - sparse_categorical_accuracy: 0.6320 - val_loss: 1.7474 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6408 - sparse_categorical_accuracy: 0.6408 - val_loss: 1.7424 - val_sparse_categorical_accuracy: 0.5295\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6521 - sparse_categorical_accuracy: 0.6306 - val_loss: 1.7482 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6526 - sparse_categorical_accuracy: 0.6299 - val_loss: 1.7626 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6444 - sparse_categorical_accuracy: 0.6456 - val_loss: 1.7588 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6375 - sparse_categorical_accuracy: 0.6469 - val_loss: 1.7509 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6424 - sparse_categorical_accuracy: 0.6388 - val_loss: 1.7365 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6442 - sparse_categorical_accuracy: 0.6374 - val_loss: 1.7407 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6324 - sparse_categorical_accuracy: 0.6476 - val_loss: 1.7524 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6441 - sparse_categorical_accuracy: 0.6381 - val_loss: 1.7458 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6286 - sparse_categorical_accuracy: 0.6503 - val_loss: 1.7592 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6411 - sparse_categorical_accuracy: 0.6401 - val_loss: 1.7441 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6187 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.7426 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6389 - sparse_categorical_accuracy: 0.6442 - val_loss: 1.7424 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6255 - sparse_categorical_accuracy: 0.6585 - val_loss: 1.7461 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6234 - sparse_categorical_accuracy: 0.6605 - val_loss: 1.7469 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6204 - sparse_categorical_accuracy: 0.6599 - val_loss: 1.7460 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6166 - sparse_categorical_accuracy: 0.6694 - val_loss: 1.7451 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6063 - sparse_categorical_accuracy: 0.6776 - val_loss: 1.7387 - val_sparse_categorical_accuracy: 0.5397\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6203 - sparse_categorical_accuracy: 0.6605 - val_loss: 1.7538 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6215 - sparse_categorical_accuracy: 0.6592 - val_loss: 1.7485 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6163 - sparse_categorical_accuracy: 0.6599 - val_loss: 1.7407 - val_sparse_categorical_accuracy: 0.5336\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6080 - sparse_categorical_accuracy: 0.6803 - val_loss: 1.7356 - val_sparse_categorical_accuracy: 0.5438\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6065 - sparse_categorical_accuracy: 0.6769 - val_loss: 1.7351 - val_sparse_categorical_accuracy: 0.5377\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6103 - sparse_categorical_accuracy: 0.6721 - val_loss: 1.7391 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6078 - sparse_categorical_accuracy: 0.6721 - val_loss: 1.7379 - val_sparse_categorical_accuracy: 0.5377\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5979 - sparse_categorical_accuracy: 0.6796 - val_loss: 1.7413 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6132 - sparse_categorical_accuracy: 0.6646 - val_loss: 1.7432 - val_sparse_categorical_accuracy: 0.5336\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6144 - sparse_categorical_accuracy: 0.6619 - val_loss: 1.7413 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6196 - sparse_categorical_accuracy: 0.6639 - val_loss: 1.7331 - val_sparse_categorical_accuracy: 0.5438\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6026 - sparse_categorical_accuracy: 0.6762 - val_loss: 1.7302 - val_sparse_categorical_accuracy: 0.5499\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5983 - sparse_categorical_accuracy: 0.6803 - val_loss: 1.7405 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6043 - sparse_categorical_accuracy: 0.6755 - val_loss: 1.7515 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5970 - sparse_categorical_accuracy: 0.6871 - val_loss: 1.7443 - val_sparse_categorical_accuracy: 0.5295\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6097 - sparse_categorical_accuracy: 0.6721 - val_loss: 1.7460 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6029 - sparse_categorical_accuracy: 0.6762 - val_loss: 1.7404 - val_sparse_categorical_accuracy: 0.5295\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5915 - sparse_categorical_accuracy: 0.6905 - val_loss: 1.7503 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5870 - sparse_categorical_accuracy: 0.6952 - val_loss: 1.7495 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5863 - sparse_categorical_accuracy: 0.6932 - val_loss: 1.7386 - val_sparse_categorical_accuracy: 0.5336\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5946 - sparse_categorical_accuracy: 0.6857 - val_loss: 1.7469 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5912 - sparse_categorical_accuracy: 0.6925 - val_loss: 1.7361 - val_sparse_categorical_accuracy: 0.5336\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5906 - sparse_categorical_accuracy: 0.6939 - val_loss: 1.7477 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5933 - sparse_categorical_accuracy: 0.6857 - val_loss: 1.7492 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5843 - sparse_categorical_accuracy: 0.6952 - val_loss: 1.7442 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5944 - sparse_categorical_accuracy: 0.6816 - val_loss: 1.7361 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5834 - sparse_categorical_accuracy: 0.6980 - val_loss: 1.7515 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5857 - sparse_categorical_accuracy: 0.6932 - val_loss: 1.7610 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5929 - sparse_categorical_accuracy: 0.6857 - val_loss: 1.7479 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5794 - sparse_categorical_accuracy: 0.7041 - val_loss: 1.7457 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5925 - sparse_categorical_accuracy: 0.6830 - val_loss: 1.7585 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5826 - sparse_categorical_accuracy: 0.6939 - val_loss: 1.7559 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5813 - sparse_categorical_accuracy: 0.6986 - val_loss: 1.7463 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5872 - sparse_categorical_accuracy: 0.6891 - val_loss: 1.7584 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5829 - sparse_categorical_accuracy: 0.6952 - val_loss: 1.7491 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5693 - sparse_categorical_accuracy: 0.7082 - val_loss: 1.7419 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5838 - sparse_categorical_accuracy: 0.6966 - val_loss: 1.7486 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5766 - sparse_categorical_accuracy: 0.7061 - val_loss: 1.7433 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5664 - sparse_categorical_accuracy: 0.7129 - val_loss: 1.7539 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5654 - sparse_categorical_accuracy: 0.7211 - val_loss: 1.7511 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5774 - sparse_categorical_accuracy: 0.7020 - val_loss: 1.7492 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5754 - sparse_categorical_accuracy: 0.7048 - val_loss: 1.7571 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5706 - sparse_categorical_accuracy: 0.7122 - val_loss: 1.7466 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5791 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.7492 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5751 - sparse_categorical_accuracy: 0.7068 - val_loss: 1.7389 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5792 - sparse_categorical_accuracy: 0.6986 - val_loss: 1.7534 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5696 - sparse_categorical_accuracy: 0.7122 - val_loss: 1.7519 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5582 - sparse_categorical_accuracy: 0.7211 - val_loss: 1.7604 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5793 - sparse_categorical_accuracy: 0.7027 - val_loss: 1.7619 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5678 - sparse_categorical_accuracy: 0.7088 - val_loss: 1.7633 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5721 - sparse_categorical_accuracy: 0.7109 - val_loss: 1.7460 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5638 - sparse_categorical_accuracy: 0.7170 - val_loss: 1.7410 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5682 - sparse_categorical_accuracy: 0.7054 - val_loss: 1.7532 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5522 - sparse_categorical_accuracy: 0.7265 - val_loss: 1.7381 - val_sparse_categorical_accuracy: 0.5377\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5826 - sparse_categorical_accuracy: 0.6986 - val_loss: 1.7478 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5602 - sparse_categorical_accuracy: 0.7177 - val_loss: 1.7426 - val_sparse_categorical_accuracy: 0.5295\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5601 - sparse_categorical_accuracy: 0.7170 - val_loss: 1.7506 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5434 - sparse_categorical_accuracy: 0.7361 - val_loss: 1.7558 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5459 - sparse_categorical_accuracy: 0.7320 - val_loss: 1.7610 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5562 - sparse_categorical_accuracy: 0.7252 - val_loss: 1.7508 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5642 - sparse_categorical_accuracy: 0.7184 - val_loss: 1.7354 - val_sparse_categorical_accuracy: 0.5418\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5598 - sparse_categorical_accuracy: 0.7224 - val_loss: 1.7509 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5558 - sparse_categorical_accuracy: 0.7252 - val_loss: 1.7408 - val_sparse_categorical_accuracy: 0.5316\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5595 - sparse_categorical_accuracy: 0.7190 - val_loss: 1.7440 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5603 - sparse_categorical_accuracy: 0.7190 - val_loss: 1.7500 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5500 - sparse_categorical_accuracy: 0.7299 - val_loss: 1.7554 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5592 - sparse_categorical_accuracy: 0.7211 - val_loss: 1.7440 - val_sparse_categorical_accuracy: 0.5275\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5613 - sparse_categorical_accuracy: 0.7170 - val_loss: 1.7613 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5437 - sparse_categorical_accuracy: 0.7408 - val_loss: 1.7508 - val_sparse_categorical_accuracy: 0.5214\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5419 - sparse_categorical_accuracy: 0.7361 - val_loss: 1.7438 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5512 - sparse_categorical_accuracy: 0.7259 - val_loss: 1.7576 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5428 - sparse_categorical_accuracy: 0.7367 - val_loss: 1.7511 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5484 - sparse_categorical_accuracy: 0.7313 - val_loss: 1.7555 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5329 - sparse_categorical_accuracy: 0.7476 - val_loss: 1.7529 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5472 - sparse_categorical_accuracy: 0.7299 - val_loss: 1.7662 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5427 - sparse_categorical_accuracy: 0.7381 - val_loss: 1.7618 - val_sparse_categorical_accuracy: 0.5153\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5486 - sparse_categorical_accuracy: 0.7293 - val_loss: 1.7669 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5432 - sparse_categorical_accuracy: 0.7327 - val_loss: 1.7654 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5416 - sparse_categorical_accuracy: 0.7367 - val_loss: 1.7676 - val_sparse_categorical_accuracy: 0.4949\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5429 - sparse_categorical_accuracy: 0.7374 - val_loss: 1.7579 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5515 - sparse_categorical_accuracy: 0.7320 - val_loss: 1.7673 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5345 - sparse_categorical_accuracy: 0.7490 - val_loss: 1.7717 - val_sparse_categorical_accuracy: 0.4949\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5349 - sparse_categorical_accuracy: 0.7435 - val_loss: 1.7694 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5453 - sparse_categorical_accuracy: 0.7347 - val_loss: 1.7620 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5537 - sparse_categorical_accuracy: 0.7252 - val_loss: 1.7623 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5278 - sparse_categorical_accuracy: 0.7551 - val_loss: 1.7521 - val_sparse_categorical_accuracy: 0.5255\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5537 - sparse_categorical_accuracy: 0.7252 - val_loss: 1.7561 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5270 - sparse_categorical_accuracy: 0.7544 - val_loss: 1.7598 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5424 - sparse_categorical_accuracy: 0.7395 - val_loss: 1.7565 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5300 - sparse_categorical_accuracy: 0.7503 - val_loss: 1.7598 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5260 - sparse_categorical_accuracy: 0.7551 - val_loss: 1.7568 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5264 - sparse_categorical_accuracy: 0.7524 - val_loss: 1.7655 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5373 - sparse_categorical_accuracy: 0.7401 - val_loss: 1.7683 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5261 - sparse_categorical_accuracy: 0.7524 - val_loss: 1.7640 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5348 - sparse_categorical_accuracy: 0.7429 - val_loss: 1.7649 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5395 - sparse_categorical_accuracy: 0.7388 - val_loss: 1.7651 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5325 - sparse_categorical_accuracy: 0.7463 - val_loss: 1.7697 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5307 - sparse_categorical_accuracy: 0.7517 - val_loss: 1.7638 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5326 - sparse_categorical_accuracy: 0.7490 - val_loss: 1.7627 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5303 - sparse_categorical_accuracy: 0.7456 - val_loss: 1.7548 - val_sparse_categorical_accuracy: 0.5132\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5244 - sparse_categorical_accuracy: 0.7565 - val_loss: 1.7524 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5307 - sparse_categorical_accuracy: 0.7449 - val_loss: 1.7596 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5225 - sparse_categorical_accuracy: 0.7571 - val_loss: 1.7659 - val_sparse_categorical_accuracy: 0.5010\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5139 - sparse_categorical_accuracy: 0.7687 - val_loss: 1.7567 - val_sparse_categorical_accuracy: 0.5092\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5462 - sparse_categorical_accuracy: 0.7279 - val_loss: 1.7596 - val_sparse_categorical_accuracy: 0.5193\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5232 - sparse_categorical_accuracy: 0.7503 - val_loss: 1.7661 - val_sparse_categorical_accuracy: 0.5031\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5294 - sparse_categorical_accuracy: 0.7510 - val_loss: 1.7617 - val_sparse_categorical_accuracy: 0.5051\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5223 - sparse_categorical_accuracy: 0.7558 - val_loss: 1.7562 - val_sparse_categorical_accuracy: 0.5112\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5198 - sparse_categorical_accuracy: 0.7605 - val_loss: 1.7727 - val_sparse_categorical_accuracy: 0.4990\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5293 - sparse_categorical_accuracy: 0.7497 - val_loss: 1.7539 - val_sparse_categorical_accuracy: 0.5173\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5317 - sparse_categorical_accuracy: 0.7463 - val_loss: 1.7344 - val_sparse_categorical_accuracy: 0.5356\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5221 - sparse_categorical_accuracy: 0.7544 - val_loss: 1.7268 - val_sparse_categorical_accuracy: 0.5519\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5280 - sparse_categorical_accuracy: 0.7476 - val_loss: 1.7448 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5297 - sparse_categorical_accuracy: 0.7456 - val_loss: 1.7454 - val_sparse_categorical_accuracy: 0.5275\n",
            "\n",
            "history dict: {'loss': [2.072993278503418, 2.0363192558288574, 2.0163965225219727, 1.9800375699996948, 1.9601094722747803, 1.94508695602417, 1.933213233947754, 1.9314751625061035, 1.911025881767273, 1.8982312679290771, 1.9039112329483032, 1.883889079093933, 1.880842924118042, 1.865458607673645, 1.8611088991165161, 1.8575600385665894, 1.846958041191101, 1.8312197923660278, 1.8245253562927246, 1.8308324813842773, 1.8196861743927002, 1.8199597597122192, 1.7985961437225342, 1.80001962184906, 1.7946159839630127, 1.7787549495697021, 1.7803481817245483, 1.7934104204177856, 1.7730780839920044, 1.7703890800476074, 1.7669706344604492, 1.7589635848999023, 1.756538987159729, 1.7548189163208008, 1.7547167539596558, 1.7402302026748657, 1.747084379196167, 1.7171376943588257, 1.7280158996582031, 1.7251183986663818, 1.7416701316833496, 1.7207798957824707, 1.7068778276443481, 1.7156437635421753, 1.7123562097549438, 1.699170708656311, 1.6980767250061035, 1.707786202430725, 1.704750418663025, 1.6853702068328857, 1.694295883178711, 1.6881365776062012, 1.6816985607147217, 1.690268635749817, 1.6747801303863525, 1.6776797771453857, 1.6754636764526367, 1.671606421470642, 1.6686111688613892, 1.6700431108474731, 1.668766975402832, 1.6610499620437622, 1.6610246896743774, 1.6612889766693115, 1.657310962677002, 1.6617871522903442, 1.6581518650054932, 1.6515413522720337, 1.6407746076583862, 1.6521345376968384, 1.6525880098342896, 1.6444488763809204, 1.6375056505203247, 1.6424392461776733, 1.6442301273345947, 1.632363200187683, 1.6440891027450562, 1.628647804260254, 1.6410506963729858, 1.618691086769104, 1.638872504234314, 1.6254562139511108, 1.6234288215637207, 1.6203668117523193, 1.6166058778762817, 1.6062822341918945, 1.6202772855758667, 1.6214607954025269, 1.6162822246551514, 1.607960820198059, 1.6064703464508057, 1.610252857208252, 1.6077746152877808, 1.597901701927185, 1.6131718158721924, 1.6143649816513062, 1.6196213960647583, 1.602579951286316, 1.5983473062515259, 1.6043450832366943, 1.5969940423965454, 1.6096669435501099, 1.6029434204101562, 1.591532826423645, 1.5869989395141602, 1.5863388776779175, 1.5946106910705566, 1.5912145376205444, 1.5906296968460083, 1.5933283567428589, 1.5843281745910645, 1.5943641662597656, 1.5834015607833862, 1.585701823234558, 1.592875599861145, 1.5794368982315063, 1.5924508571624756, 1.5826047658920288, 1.5812735557556152, 1.5872076749801636, 1.5829259157180786, 1.5692776441574097, 1.5837945938110352, 1.5765836238861084, 1.5663782358169556, 1.5653904676437378, 1.5774271488189697, 1.5753988027572632, 1.5706443786621094, 1.579134225845337, 1.5751177072525024, 1.5791947841644287, 1.5695523023605347, 1.5581560134887695, 1.5793466567993164, 1.5677863359451294, 1.572103500366211, 1.5637714862823486, 1.5682153701782227, 1.5521641969680786, 1.582623839378357, 1.560158610343933, 1.560118556022644, 1.5434303283691406, 1.5459462404251099, 1.5562198162078857, 1.5642280578613281, 1.559849500656128, 1.5557911396026611, 1.5594934225082397, 1.5603140592575073, 1.549988031387329, 1.5591504573822021, 1.5612794160842896, 1.5437248945236206, 1.5419360399246216, 1.5511587858200073, 1.5427939891815186, 1.548384666442871, 1.5329318046569824, 1.5472244024276733, 1.542702317237854, 1.548552393913269, 1.5432393550872803, 1.541556715965271, 1.5428872108459473, 1.551469326019287, 1.534466028213501, 1.534895658493042, 1.5453121662139893, 1.5536649227142334, 1.5277632474899292, 1.55368173122406, 1.5270228385925293, 1.5423723459243774, 1.5299675464630127, 1.5260320901870728, 1.5264456272125244, 1.537304401397705, 1.5260719060897827, 1.5347537994384766, 1.5394760370254517, 1.5325343608856201, 1.5306514501571655, 1.5326426029205322, 1.5303322076797485, 1.5243958234786987, 1.530726671218872, 1.5224651098251343, 1.5138919353485107, 1.5461870431900024, 1.5231809616088867, 1.5293830633163452, 1.5222924947738647, 1.5198386907577515, 1.529305338859558, 1.531672477722168, 1.5220967531204224, 1.5280004739761353, 1.5296887159347534], 'sparse_categorical_accuracy': [0.14149659872055054, 0.21360544860363007, 0.24421769380569458, 0.2925170063972473, 0.31700679659843445, 0.33401361107826233, 0.33877551555633545, 0.34965986013412476, 0.3680272102355957, 0.37755101919174194, 0.3741496503353119, 0.4000000059604645, 0.3965986371040344, 0.41428571939468384, 0.42312926054000854, 0.4204081594944, 0.4333333373069763, 0.4544217586517334, 0.4632652997970581, 0.4523809552192688, 0.4700680375099182, 0.46394556760787964, 0.4918367266654968, 0.48163264989852905, 0.4863945543766022, 0.5047619342803955, 0.49863946437835693, 0.49251699447631836, 0.5108843445777893, 0.5081632733345032, 0.5204081535339355, 0.5244898200035095, 0.5326530337333679, 0.5319727659225464, 0.523809552192688, 0.5564625859260559, 0.538095235824585, 0.5761904716491699, 0.5571428537368774, 0.5537415146827698, 0.5401360392570496, 0.5666666626930237, 0.58299320936203, 0.5693877339363098, 0.5680271983146667, 0.5897959470748901, 0.5877550840377808, 0.5768707394599915, 0.5802721381187439, 0.5986394286155701, 0.5823129415512085, 0.5911564826965332, 0.6047618985176086, 0.5952380895614624, 0.6108843684196472, 0.602721095085144, 0.6129251718521118, 0.6129251718521118, 0.6163265109062195, 0.6108843684196472, 0.6115646362304688, 0.6204081773757935, 0.6251700520515442, 0.6217687129974365, 0.6244897842407227, 0.621088445186615, 0.6204081773757935, 0.6319727897644043, 0.640816330909729, 0.6306122541427612, 0.6299319863319397, 0.6455782055854797, 0.6469388008117676, 0.6387755274772644, 0.6374149918556213, 0.6476190686225891, 0.6380952596664429, 0.6503401398658752, 0.6401360630989075, 0.6666666865348816, 0.6442176699638367, 0.6585034132003784, 0.660544216632843, 0.6598639488220215, 0.6693877577781677, 0.6775510311126709, 0.660544216632843, 0.6591836810112, 0.6598639488220215, 0.680272102355957, 0.6768707633018494, 0.6721088290214539, 0.6721088290214539, 0.6795918345451355, 0.6646258234977722, 0.6619047522544861, 0.6639455556869507, 0.6761904954910278, 0.680272102355957, 0.6755102276802063, 0.6870748400688171, 0.6721088290214539, 0.6761904954910278, 0.6904761791229248, 0.6952381134033203, 0.6931972503662109, 0.6857143044471741, 0.6925169825553894, 0.6938775777816772, 0.6857143044471741, 0.6952381134033203, 0.6816326379776001, 0.6979591846466064, 0.6931972503662109, 0.6857143044471741, 0.704081654548645, 0.6829931735992432, 0.6938775777816772, 0.698639452457428, 0.6891156435012817, 0.6952381134033203, 0.7081632614135742, 0.6965986490249634, 0.7061224579811096, 0.7129251956939697, 0.7210884094238281, 0.7020407915115356, 0.7047619223594666, 0.7122448682785034, 0.699999988079071, 0.7068027257919312, 0.698639452457428, 0.7122448682785034, 0.7210884094238281, 0.7027210593223572, 0.7088435292243958, 0.7108843326568604, 0.7170068025588989, 0.7054421901702881, 0.7265306115150452, 0.698639452457428, 0.7176870703697205, 0.7170068025588989, 0.7360544204711914, 0.7319728136062622, 0.7251700758934021, 0.718367338180542, 0.722449004650116, 0.7251700758934021, 0.7190476059913635, 0.7190476059913635, 0.7299319505691528, 0.7210884094238281, 0.7170068025588989, 0.7408163547515869, 0.7360544204711914, 0.7258503437042236, 0.7367346882820129, 0.7312925457954407, 0.7476190328598022, 0.7299319505691528, 0.738095223903656, 0.7292516827583313, 0.7326530814170837, 0.7367346882820129, 0.7374149560928345, 0.7319728136062622, 0.7489795684814453, 0.743537425994873, 0.7346938848495483, 0.7251700758934021, 0.7551020383834839, 0.7251700758934021, 0.7544217705726624, 0.7394557595252991, 0.7503401637077332, 0.7551020383834839, 0.7523809671401978, 0.7401360273361206, 0.7523809671401978, 0.7428571581840515, 0.7387754917144775, 0.7462584972381592, 0.7517006993293762, 0.7489795684814453, 0.7455782294273376, 0.756462574005127, 0.7448979616165161, 0.7571428418159485, 0.7687074542045593, 0.7278911471366882, 0.7503401637077332, 0.7510204315185547, 0.7557823061943054, 0.7605442404747009, 0.7496598362922668, 0.7462584972381592, 0.7544217705726624, 0.7476190328598022, 0.7455782294273376], 'val_loss': [2.0417468547821045, 1.9938167333602905, 1.9567667245864868, 1.934526801109314, 1.9198609590530396, 1.9037235975265503, 1.8903121948242188, 1.8802484273910522, 1.8739964962005615, 1.8599294424057007, 1.8482862710952759, 1.8425482511520386, 1.836522102355957, 1.8295385837554932, 1.8292968273162842, 1.822317361831665, 1.8252149820327759, 1.824416995048523, 1.8146315813064575, 1.812581181526184, 1.805849552154541, 1.8029996156692505, 1.802377462387085, 1.793328046798706, 1.8053427934646606, 1.7884827852249146, 1.7899659872055054, 1.779252052307129, 1.7761740684509277, 1.7889504432678223, 1.774449110031128, 1.7795355319976807, 1.76022207736969, 1.763458013534546, 1.768778681755066, 1.7692935466766357, 1.7679352760314941, 1.7600175142288208, 1.7767326831817627, 1.7728768587112427, 1.7709139585494995, 1.77152681350708, 1.7637563943862915, 1.7650671005249023, 1.7768211364746094, 1.7722506523132324, 1.7721052169799805, 1.7643518447875977, 1.7661381959915161, 1.770930528640747, 1.7549391984939575, 1.7496942281723022, 1.7470906972885132, 1.7452237606048584, 1.7489607334136963, 1.754889965057373, 1.7456668615341187, 1.7425141334533691, 1.7489148378372192, 1.7530517578125, 1.7493478059768677, 1.7522497177124023, 1.7613276243209839, 1.7536286115646362, 1.7457008361816406, 1.7483723163604736, 1.7387944459915161, 1.7474327087402344, 1.7424403429031372, 1.7481764554977417, 1.7625874280929565, 1.7587562799453735, 1.7508620023727417, 1.7365188598632812, 1.7407346963882446, 1.7523735761642456, 1.7457945346832275, 1.7592270374298096, 1.7440671920776367, 1.7426135540008545, 1.7423635721206665, 1.746098518371582, 1.7469136714935303, 1.7459815740585327, 1.7451283931732178, 1.7386705875396729, 1.7537572383880615, 1.7484859228134155, 1.7407076358795166, 1.735615849494934, 1.7351418733596802, 1.7390551567077637, 1.737908124923706, 1.7412904500961304, 1.7431697845458984, 1.7412978410720825, 1.7331011295318604, 1.730241060256958, 1.7404760122299194, 1.7515259981155396, 1.7442867755889893, 1.7459626197814941, 1.740380048751831, 1.750342607498169, 1.7494508028030396, 1.7385679483413696, 1.7469263076782227, 1.7360917329788208, 1.747684121131897, 1.749194860458374, 1.744236707687378, 1.7361069917678833, 1.7514582872390747, 1.7610169649124146, 1.747944951057434, 1.7457315921783447, 1.758455753326416, 1.7558960914611816, 1.7463188171386719, 1.7584254741668701, 1.749112606048584, 1.7419369220733643, 1.748628854751587, 1.7433077096939087, 1.753880500793457, 1.751143455505371, 1.7492488622665405, 1.757067084312439, 1.7465541362762451, 1.7492105960845947, 1.738908290863037, 1.7533828020095825, 1.7518682479858398, 1.7603836059570312, 1.761873722076416, 1.7633464336395264, 1.7459906339645386, 1.7409946918487549, 1.753171443939209, 1.7380602359771729, 1.7478288412094116, 1.7426127195358276, 1.750551700592041, 1.7558037042617798, 1.7610280513763428, 1.7508078813552856, 1.735438585281372, 1.7508623600006104, 1.7407656908035278, 1.744048833847046, 1.7499535083770752, 1.7554489374160767, 1.7439806461334229, 1.7612535953521729, 1.7507823705673218, 1.7437647581100464, 1.7575573921203613, 1.751112461090088, 1.7555478811264038, 1.7528977394104004, 1.766206979751587, 1.7617992162704468, 1.76694917678833, 1.765376091003418, 1.7676310539245605, 1.7579336166381836, 1.7672696113586426, 1.7716742753982544, 1.7694065570831299, 1.7620270252227783, 1.7622987031936646, 1.7520643472671509, 1.7560564279556274, 1.7598294019699097, 1.7564777135849, 1.7597862482070923, 1.7568374872207642, 1.765453815460205, 1.7683258056640625, 1.7640305757522583, 1.764864206314087, 1.7651455402374268, 1.7696833610534668, 1.7637966871261597, 1.762725591659546, 1.7547661066055298, 1.7523670196533203, 1.7596226930618286, 1.7659058570861816, 1.756676435470581, 1.7596341371536255, 1.766135811805725, 1.7617262601852417, 1.7561559677124023, 1.7726681232452393, 1.7539474964141846, 1.7343859672546387, 1.726828694343567, 1.7447952032089233, 1.7453535795211792], 'val_sparse_categorical_accuracy': [0.30346232652664185, 0.2993890047073364, 0.3136456310749054, 0.32586556673049927, 0.3360488712787628, 0.3482688367366791, 0.3747454285621643, 0.376782089471817, 0.3890020251274109, 0.4073319733142853, 0.42362526059150696, 0.42158859968185425, 0.4358452260494232, 0.43991854786872864, 0.4338085651397705, 0.46435844898223877, 0.4541751444339752, 0.4460285007953644, 0.45824846625328064, 0.4663951098918915, 0.48268839716911316, 0.4704684317111969, 0.4684317708015442, 0.48472505807876587, 0.4541751444339752, 0.4887983798980713, 0.47861507534980774, 0.49898168444633484, 0.505091667175293, 0.48268839716911316, 0.49694502353668213, 0.5030549764633179, 0.505091667175293, 0.5152749419212341, 0.5071282982826233, 0.49898168444633484, 0.505091667175293, 0.5091649889945984, 0.490835040807724, 0.4949083626270294, 0.5010183453559875, 0.49898168444633484, 0.5071282982826233, 0.5010183453559875, 0.48065173625946045, 0.4867617189884186, 0.49898168444633484, 0.505091667175293, 0.5030549764633179, 0.49694502353668213, 0.5152749419212341, 0.5213849544525146, 0.5193482637405396, 0.5193482637405396, 0.5193482637405396, 0.5132383108139038, 0.5254582762718201, 0.5274949073791504, 0.523421585559845, 0.5152749419212341, 0.5295315384864807, 0.5173116326332092, 0.49694502353668213, 0.5091649889945984, 0.523421585559845, 0.523421585559845, 0.5356415510177612, 0.5152749419212341, 0.5295315384864807, 0.5152749419212341, 0.5112016201019287, 0.5071282982826233, 0.5274949073791504, 0.5356415510177612, 0.5356415510177612, 0.5193482637405396, 0.5193482637405396, 0.5112016201019287, 0.5254582762718201, 0.5213849544525146, 0.523421585559845, 0.5213849544525146, 0.5193482637405396, 0.5173116326332092, 0.5254582762718201, 0.5397148728370667, 0.5132383108139038, 0.5274949073791504, 0.5336048603057861, 0.5437881946563721, 0.5376781821250916, 0.5356415510177612, 0.5376781821250916, 0.5254582762718201, 0.5336048603057861, 0.523421585559845, 0.5437881946563721, 0.5498981475830078, 0.5213849544525146, 0.5193482637405396, 0.5295315384864807, 0.5254582762718201, 0.5295315384864807, 0.5213849544525146, 0.5193482637405396, 0.5336048603057861, 0.5193482637405396, 0.5336048603057861, 0.5132383108139038, 0.5274949073791504, 0.5193482637405396, 0.5274949073791504, 0.5071282982826233, 0.5030549764633179, 0.523421585559845, 0.5193482637405396, 0.49898168444633484, 0.5152749419212341, 0.5193482637405396, 0.5152749419212341, 0.5254582762718201, 0.5254582762718201, 0.5173116326332092, 0.523421585559845, 0.5071282982826233, 0.523421585559845, 0.5173116326332092, 0.5193482637405396, 0.5274949073791504, 0.523421585559845, 0.5356415510177612, 0.5112016201019287, 0.5152749419212341, 0.5213849544525146, 0.5030549764633179, 0.49898168444633484, 0.5152749419212341, 0.5356415510177612, 0.5152749419212341, 0.5376781821250916, 0.5274949073791504, 0.5295315384864807, 0.5213849544525146, 0.5112016201019287, 0.5091649889945984, 0.5213849544525146, 0.541751503944397, 0.523421585559845, 0.5315682291984558, 0.523421585559845, 0.5173116326332092, 0.505091667175293, 0.5274949073791504, 0.5030549764633179, 0.5213849544525146, 0.5193482637405396, 0.5091649889945984, 0.5173116326332092, 0.5112016201019287, 0.523421585559845, 0.5071282982826233, 0.5152749419212341, 0.5010183453559875, 0.5030549764633179, 0.4949083626270294, 0.5132383108139038, 0.5010183453559875, 0.4949083626270294, 0.5010183453559875, 0.5030549764633179, 0.5132383108139038, 0.5254582762718201, 0.5173116326332092, 0.5112016201019287, 0.5193482637405396, 0.5091649889945984, 0.5173116326332092, 0.5010183453559875, 0.49898168444633484, 0.5091649889945984, 0.5010183453559875, 0.5071282982826233, 0.5030549764633179, 0.5071282982826233, 0.5091649889945984, 0.5132383108139038, 0.523421585559845, 0.505091667175293, 0.5010183453559875, 0.5091649889945984, 0.5193482637405396, 0.5030549764633179, 0.505091667175293, 0.5112016201019287, 0.49898168444633484, 0.5173116326332092, 0.5356415510177612, 0.5519348382949829, 0.523421585559845, 0.5274949073791504]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSSwmBO8eIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ccb53a80-3c34-4a58-ac46-d68d09e33d78"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.9889 - sparse_categorical_accuracy: 0.2648\n",
            "test loss, test acc: [1.9889146089553833, 0.26476576924324036]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlKxG5ZF8r8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}